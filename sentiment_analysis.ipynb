{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# pd.set_option(\"display.max_rows\",2000)\n",
    "# pd.set_option(\"display./max_seq_items\",2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### each row in our data has these features:\n",
    "    - unique PhraseId\n",
    "    - original sentenceId\n",
    "    - Pharse\n",
    "    - label- sentiment \n",
    "\n",
    "sentiment is from 0 - very negative to 4- very positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenize each pharse to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tokenizing import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tok = Tokenizer(preserve_case=False)\n",
    "data['Phrase_tokens'] = data['Phrase'].apply(tok.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>[a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment                                      Phrase_tokens  \n",
       "0          1  [a, series, of, escapades, demonstrating, the,...  \n",
       "1          2  [a, series, of, escapades, demonstrating, the,...  \n",
       "2          2                                        [a, series]  \n",
       "3          2                                                [a]  \n",
       "4          2                                           [series]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_dict = {}\n",
    "max_train = 140353 #use only train data to build sentiment dict\n",
    "iterator = data.iterrows()\n",
    "  \n",
    "for _ in range(max_train):  \n",
    "    index,row = iterator.next()\n",
    "    word_list = row['Phrase_tokens']\n",
    "    if len(word_list)==1:\n",
    "        sentiment_dict[word_list[0].lower()] = data['Sentiment'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from phrases\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "print stopwords.words(\"english\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Phrase_tokens'] = data['Phrase_tokens'].apply(lambda words:[w for w in words if not w in stopwords.words(\"english\") and w.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "      <td>[escapades, demonstrating, adage, good, goose]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "      <td>[escapades, demonstrating, adage, good, goose]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "      <td>[escapades]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[demonstrating, adage, good, goose]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "5         6           1  of escapades demonstrating the adage that what...   \n",
       "6         7           1                                                 of   \n",
       "7         8           1  escapades demonstrating the adage that what is...   \n",
       "8         9           1                                          escapades   \n",
       "9        10           1  demonstrating the adage that what is good for ...   \n",
       "\n",
       "   Sentiment                                      Phrase_tokens  \n",
       "0          1  [series, escapades, demonstrating, adage, good...  \n",
       "1          2  [series, escapades, demonstrating, adage, good...  \n",
       "2          2                                           [series]  \n",
       "3          2                                                 []  \n",
       "4          2                                           [series]  \n",
       "5          2     [escapades, demonstrating, adage, good, goose]  \n",
       "6          2                                                 []  \n",
       "7          2     [escapades, demonstrating, adage, good, goose]  \n",
       "8          2                                        [escapades]  \n",
       "9          2                [demonstrating, adage, good, goose]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Approch 1: create features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we combine our dataset with the Sentiwordnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### use the following features to represent each sentense:\n",
    "    - avg sentiment of the words in the pharse\n",
    "    - max sentiment in phrase\n",
    "    - min sentiment in pharse\n",
    "    - binary indicators of positive words and negative words from SentiWordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min,max,avg calc of sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sentiment_dict = {}\n",
    "# max_train = 140353 #use only train data tot build sentiment dict\n",
    "\n",
    "data = pd.DataFrame(data[data['Phrase_tokens'].str.len() >0])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# iterator = data.iterrows()\n",
    "  \n",
    "# for _ in range(max_train):  \n",
    "#     index,row = iterator.next()\n",
    "#     word_list = row['Phrase_tokens']\n",
    "#     if len(word_list)==1:\n",
    "#         sentiment_dict[word_list[0].lower()] = data['Sentiment'][index]\n",
    "\n",
    "# data = pd.DataFrame(data[data['Phrase_tokens'].str.len() >0])\n",
    "# data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count each term appearance for TF-IDF weights\n",
    "count_dict = {}\n",
    "for i,word_list in enumerate(data['Phrase_tokens'][:max_train]):\n",
    "    for word in word_list:\n",
    "        word = word.lower()\n",
    "        if count_dict.has_key(word):\n",
    "           count_dict[word] = count_dict[word] + 1\n",
    "        else:\n",
    "            count_dict[word] = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_document_train = max_train\n",
    "\n",
    "def TF_IDF_weighting(word):\n",
    "    if count_dict.has_key(word):\n",
    "        return np.log(num_document_train/(count_dict[word]))\n",
    "    else: return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def creat_sentiment_list(word_list):\n",
    "    sent_list = []\n",
    "    for word in word_list:\n",
    "        word_sent  = sentiment_dict.get(word.lower(),2)\n",
    "        #weighted_word_sent = word_sent *TF_IDF_weighting(word.lower())\n",
    "        sent_list.append(word_sent)\n",
    "    return sent_list\n",
    "\n",
    "data['sentiment list'] = data['Phrase_tokens'].apply(creat_sentiment_list)\n",
    "#data['avg sentiment'] = data['sentiment list'].apply(lambda x: sum(x)/float(len(x)))\n",
    "data['max sentiment'] = data['sentiment list'].apply(lambda x: max(x))\n",
    "data['min sentiment'] =  data['sentiment list'].apply(lambda x: min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_tokens</th>\n",
       "      <th>sentiment list</th>\n",
       "      <th>max sentiment</th>\n",
       "      <th>min sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[2, 2, 2, 2, 3, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "      <td>[escapades, demonstrating, adage, good, goose]</td>\n",
       "      <td>[2, 2, 2, 3, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         5           1                                             series   \n",
       "4         6           1  of escapades demonstrating the adage that what...   \n",
       "\n",
       "   Sentiment                                      Phrase_tokens  \\\n",
       "0          1  [series, escapades, demonstrating, adage, good...   \n",
       "1          2  [series, escapades, demonstrating, adage, good...   \n",
       "2          2                                           [series]   \n",
       "3          2                                           [series]   \n",
       "4          2     [escapades, demonstrating, adage, good, goose]   \n",
       "\n",
       "                                  sentiment list  max sentiment  min sentiment  \n",
       "0  [2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2]              3              2  \n",
       "1                             [2, 2, 2, 2, 3, 2]              3              2  \n",
       "2                                            [2]              2              2  \n",
       "3                                            [2]              2              2  \n",
       "4                                [2, 2, 2, 3, 2]              3              2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_sentiment(word_list,sentiment_list):\n",
    "    weight_list = []\n",
    "    for word in word_list:\n",
    "        word_TF_IDF =  TF_IDF_weighting(word.lower())\n",
    "        weight_list.append(word_TF_IDF)\n",
    "    weight_sum = sum(weight_list)\n",
    "    return np.dot(sentiment_list,weight_list)/weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weighted_avg = []\n",
    "for word_list,sentiment_list in zip(data['Phrase_tokens'],data['sentiment list']):\n",
    "    result = weight_sentiment(word_list,sentiment_list)\n",
    "    weighted_avg.append(result)\n",
    "data['avg sentiment']=  pd.Series(weighted_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_tokens</th>\n",
       "      <th>sentiment list</th>\n",
       "      <th>max sentiment</th>\n",
       "      <th>min sentiment</th>\n",
       "      <th>avg sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[2, 2, 2, 2, 3, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.092056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "      <td>[escapades, demonstrating, adage, good, goose]</td>\n",
       "      <td>[2, 2, 2, 3, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.105791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         5           1                                             series   \n",
       "4         6           1  of escapades demonstrating the adage that what...   \n",
       "\n",
       "   Sentiment                                      Phrase_tokens  \\\n",
       "0          1  [series, escapades, demonstrating, adage, good...   \n",
       "1          2  [series, escapades, demonstrating, adage, good...   \n",
       "2          2                                           [series]   \n",
       "3          2                                           [series]   \n",
       "4          2     [escapades, demonstrating, adage, good, goose]   \n",
       "\n",
       "                                  sentiment list  max sentiment  \\\n",
       "0  [2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2]              3   \n",
       "1                             [2, 2, 2, 2, 3, 2]              3   \n",
       "2                                            [2]              2   \n",
       "3                                            [2]              2   \n",
       "4                                [2, 2, 2, 3, 2]              3   \n",
       "\n",
       "   min sentiment  avg sentiment  \n",
       "0              2       2.172159  \n",
       "1              2       2.092056  \n",
       "2              2       2.000000  \n",
       "3              2       2.000000  \n",
       "4              2       2.105791  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binary indicators of positivity/negativity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain about sentiwordnet and thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh = 0.8\n",
    "pos = [] #list of positive words\n",
    "neg = [] # list of negative words\n",
    "with open('SentiWordNet.txt','r') as f:\n",
    "    for line in f:\n",
    "        if line[0]=='#' or line[0].isspace() : continue #skip comment rows in database  \n",
    "        e = line.split('\\t')\n",
    "        if float(e[2])>=thresh: pos.append(e[4].split('#')[0])\n",
    "        elif float(e[3])>=thresh: neg.append(e[4].split('#')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for senti_word in pos+neg:\n",
    "    \n",
    "    def check_if_word_exist(word_list):\n",
    "        lower_pharse = [x.lower() for x in word_list]\n",
    "        return senti_word in lower_pharse\n",
    "    \n",
    "    data['contain_'+senti_word] = data['Phrase_tokens'].apply(lambda word_list: check_if_word_exist(word_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_tokens</th>\n",
       "      <th>sentiment list</th>\n",
       "      <th>max sentiment</th>\n",
       "      <th>min sentiment</th>\n",
       "      <th>avg sentiment</th>\n",
       "      <th>contain_veracious</th>\n",
       "      <th>...</th>\n",
       "      <th>contain_resent</th>\n",
       "      <th>contain_pound</th>\n",
       "      <th>contain_mislead</th>\n",
       "      <th>contain_desensitize</th>\n",
       "      <th>contain_burn</th>\n",
       "      <th>contain_twinge</th>\n",
       "      <th>contain_stink</th>\n",
       "      <th>contain_smell</th>\n",
       "      <th>contain_trouble</th>\n",
       "      <th>contain_humbug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172159</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[2, 2, 2, 2, 3, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.092056</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "      <td>[escapades, demonstrating, adage, good, goose]</td>\n",
       "      <td>[2, 2, 2, 3, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.105791</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 432 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         5           1                                             series   \n",
       "4         6           1  of escapades demonstrating the adage that what...   \n",
       "\n",
       "   Sentiment                                      Phrase_tokens  \\\n",
       "0          1  [series, escapades, demonstrating, adage, good...   \n",
       "1          2  [series, escapades, demonstrating, adage, good...   \n",
       "2          2                                           [series]   \n",
       "3          2                                           [series]   \n",
       "4          2     [escapades, demonstrating, adage, good, goose]   \n",
       "\n",
       "                                  sentiment list  max sentiment  \\\n",
       "0  [2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2]              3   \n",
       "1                             [2, 2, 2, 2, 3, 2]              3   \n",
       "2                                            [2]              2   \n",
       "3                                            [2]              2   \n",
       "4                                [2, 2, 2, 3, 2]              3   \n",
       "\n",
       "   min sentiment  avg sentiment contain_veracious      ...        \\\n",
       "0              2       2.172159             False      ...         \n",
       "1              2       2.092056             False      ...         \n",
       "2              2       2.000000             False      ...         \n",
       "3              2       2.000000             False      ...         \n",
       "4              2       2.105791             False      ...         \n",
       "\n",
       "  contain_resent contain_pound contain_mislead contain_desensitize  \\\n",
       "0          False         False           False               False   \n",
       "1          False         False           False               False   \n",
       "2          False         False           False               False   \n",
       "3          False         False           False               False   \n",
       "4          False         False           False               False   \n",
       "\n",
       "  contain_burn contain_twinge contain_stink contain_smell contain_trouble  \\\n",
       "0        False          False         False         False           False   \n",
       "1        False          False         False         False           False   \n",
       "2        False          False         False         False           False   \n",
       "3        False          False         False         False           False   \n",
       "4        False          False         False         False           False   \n",
       "\n",
       "  contain_humbug  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "\n",
       "[5 rows x 432 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check results of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on ~90% of the data and check on the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select only features columms. split to train and test datasets\n",
    "contain_list = [column for column in data.columns.values if column.startswith('contain') ]\n",
    "feature_list = ['avg sentiment', 'max sentiment', 'min sentiment'] + contain_list\n",
    "features = data[feature_list]\n",
    "features = normalize(features)\n",
    "x_train,y_train = features[:max_train],data['Sentiment'][:max_train]\n",
    "x_test,y_test = features[max_train:],data['Sentiment'][max_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = OneVsRestClassifier(RandomForestClassifier(n_jobs=3))\n",
    "model.fit(x_train,y_train)\n",
    "predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.16      0.11      0.13       606\n",
      "          1       0.31      0.18      0.23      2442\n",
      "          2       0.58      0.77      0.66      5882\n",
      "          3       0.32      0.24      0.28      2503\n",
      "          4       0.16      0.15      0.15       719\n",
      "\n",
      "avg / total       0.43      0.47      0.44     12152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating vocabulary\n",
    "NUM_OF_PHARSE = data.shape[0]\n",
    "vocab = []\n",
    "for i in range(NUM_OF_PHARSE):\n",
    "    vocab.extend(data['Phrase'].iloc[i])\n",
    "vocab = list(set(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Bag_of_Words']=pd.Series(0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag_of_words = np.zeros((NUM_OF_PHARSE,len(vocab)))\n",
    "for i in range(NUM_OF_PHARSE):\n",
    "    for word in data['Phrase'][i]:\n",
    "        indx = vocab.index(word)\n",
    "        bag_of_words[i][indx] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Training the random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 5) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( bag_of_words, data[\"Sentiment\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
